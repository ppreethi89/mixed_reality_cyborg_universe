// Copyright (c) 2010-2017 CereProc Ltd.
//
// Permission is hereby granted, free of charge, to any person obtaining
// a copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to
// permit persons to whom the Software is furnished to do so, subject to
// the following conditions:
//
// The above copyright notice and this permission notice shall be
// included in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
// EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
// NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE
// LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
// OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
// WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

//
// TtsCallback.cs - synthesis tool for C# with callbacks
//

using System;
using System.IO;
using System.Linq;
using System.Threading;

using System.Collections;
using System.Collections.Generic;
using UnityEngine;
using AOT;

// For animation timings
class Viseme
{
    public string name;
    public float start;
}

// Generated by CPRC thread
class RawPhrase
{
    public float[] floatArr;
    public List<Viseme> visemeList;
}

public class TTS_unity : MonoBehaviour {
    // Voice Load Mode
    CPRC_VOICE_LOAD_TYPE load_mode = CPRC_VOICE_LOAD_TYPE.CPRC_VOICE_LOAD_EMB_AUDIO;

    // TTS engine
    SWIGTYPE_p_CPRCEN_engine eng;

    AudioSource audiosource;

    // Initialize viseme list, phrase queue and peeker
    static Queue<RawPhrase> RawPhrases = new Queue<RawPhrase>();
    RawPhrase currRawPhrase;
	int sampleRate;

    void Start()
    {
        string voice_file;
        string license_file;
        string root_cert_file;
        string cert_file;
        string key_file;

        voice_file = Application.streamingAssetsPath + "/cerevoice_PeterCereWave_16k_cerewave.voice";
        license_file = Application.streamingAssetsPath + "/960F0CFF-C45B-47A8-B117-7F7E2D24A4FE_PCW_client.lic";
        root_cert_file = Application.streamingAssetsPath + "/root_certificate.pem";
        cert_file = Application.streamingAssetsPath + "/960F0CFF-C45B-47A8-B117-7F7E2D24A4FE_PCW_client.crt";
        key_file = Application.streamingAssetsPath + "/960F0CFF-C45B-47A8-B117-7F7E2D24A4FE_PCW_client.key";

        if (Application.platform == RuntimePlatform.Android)
        {
            // Need to uncompress the files to read them
            string voice_compressed = voice_file;
            string license_compressed = license_file;
            string root_cert_compressed = root_cert_file;
            string client_cert_compressed = cert_file;
            string client_key_compressed = key_file;
            voice_file = Application.persistentDataPath + "/tts.voice";
            license_file = Application.persistentDataPath + "/license.lic";
            root_cert_file = Application.persistentDataPath + "/root_certificate.pem";
            cert_file = Application.persistentDataPath + "/Voice123_client_certificate.pem.crt";
            key_file = Application.persistentDataPath + "/Voice123_client_key.key";
            Debug.Log("voice file " + voice_file + " to copy from " + voice_compressed);
            Debug.Log("license file " + license_file + " to copy from " + license_compressed);
            Debug.Log("license server certificate file " + root_cert_file + " to copy from " + root_cert_compressed);
            Debug.Log("client certificate file " + cert_file + " to copy from " + client_cert_compressed);
            Debug.Log("client key file " + key_file + " to copy from " + client_key_compressed);

            WWW lreader;
            lreader = new WWW(license_compressed);
            while (!lreader.isDone) { }
            Debug.Log("writing " + lreader.bytesDownloaded + " bytes to license file");
            File.WriteAllBytes(license_file, lreader.bytes);

            WWW rreader;
            rreader = new WWW(root_cert_compressed);
            while (!rreader.isDone) { }
            Debug.Log("writing " + rreader.bytesDownloaded + " bytes to license server certificate file");
            File.WriteAllBytes(root_cert_file, rreader.bytes);

            WWW creader;
            creader = new WWW(client_cert_compressed);
            while (!creader.isDone) { }
            Debug.Log("writing " + creader.bytesDownloaded + " bytes to client certificate file");
            File.WriteAllBytes(cert_file, creader.bytes);

            WWW kreader;
            kreader = new WWW(client_key_compressed);
            while (!kreader.isDone) { }
            Debug.Log("writing " + kreader.bytesDownloaded + " bytes to client key file");
            File.WriteAllBytes(key_file, kreader.bytes);

            WWW vreader;
            vreader = new WWW(voice_compressed);
            while (!vreader.isDone) { }
            // Note that large voices may cause memory issues
            Debug.Log("writing " + vreader.bytesDownloaded + " bytes to voice file");
            File.WriteAllBytes(voice_file, vreader.bytes);
        }

        Debug.Log("voice file is " + voice_file);
        Debug.Log("license file is " + license_file);
        Debug.Log("license server certificate file is " + root_cert_file);
        Debug.Log("client certificate file is " + cert_file);
        Debug.Log("client key file is " + key_file);

        // Create the TTS engine
        eng  = cerevoice_eng.CPRCEN_engine_new();
        //eng2 = UWP_cerevoice_eng.
        
        int ret;
        // Load voice into engine
        ret = cerevoice_eng.CPRCEN_engine_load_voice(eng, voice_file, "", load_mode, license_file, root_cert_file, cert_file, key_file);
        if (ret > 0)
        {
            Debug.Log("voice load returned " + ret);
        } else
        {
            Debug.LogError("failed to load voice");
        }
        // Make reference to AudioSource attached to TTS GameObject
        audiosource = GetComponent<AudioSource>();

        if (ret > 0)
	{
	    // Self contained example synthesis request. For deployment
	    // with threading, low latency, and viseme support, see the
	    // callback sections below.
            int wav_len; // number of samples
            int chan; // synthesis channel
            int srate; // ouput sample rate
            SWIGTYPE_p_CPRC_abuf abuf; // CereVoice audio buffer
            string input = "Welcome to the CereVoice Unity Demo";

            Debug.Log("synthesising a test input");
            // Open a channel and synthesise to an audio buffer
            chan = cerevoice_eng.CPRCEN_engine_open_channel(eng, "", "", "", "");
            srate = Convert.ToInt32(cerevoice_eng.CPRCEN_channel_get_voice_info(eng, chan, "SAMPLE_RATE"));
            abuf = cerevoice_eng.CPRCEN_engine_channel_speak(eng, chan, input, input.Length, 1);
            wav_len = cerevoice_eng.CPRC_abuf_wav_sz(abuf);
            Debug.Log("done synthesising test input, output wav length " + wav_len);

            // Convert to float for Unity playback
            float[] floatArr = new float[wav_len];
            int i;
            for (i = 0; i < wav_len; i++) 
            {
               floatArr[i] = cerevoice_eng.CPRC_abuf_wav(abuf, i) / (float)32768.0;
            }
            // Clean up channel
            cerevoice_eng.CPRCEN_engine_channel_close(eng, chan);

            // Create and play a Unity AudioClip 
            Debug.Log("creating playback clip");
            AudioClip testclip = AudioClip.Create("testclip", floatArr.Length, 1, srate, false);
            testclip.SetData(floatArr, 0);
            audiosource.clip = testclip;
            Debug.Log("playing test input");
            audiosource.Play();
        }
    }

    // This will be called when text is input
    public void TTS(string input)
    {
        // Clear queues and stop any animation coroutines (in case of interruption)
        RawPhrases.Clear();
        audiosource.Stop();
        StopAllCoroutines();

        // Create and start CPRC thread
        Thread CPRCthread= new Thread(() => Cerevoice(input));
        CPRCthread.Start();
    }

    // Method called within CPRC thread
    void Cerevoice(string input)
    {
        // Open a channel
        // Optionally the language, region, voice name, and sample rate can be
        // specified - allows switching when multiple voices are loaded.
        int chan;
        chan = cerevoice_eng.CPRCEN_engine_open_channel(eng, "", "", "", "");
        sampleRate = Convert.ToInt32(cerevoice_eng.CPRCEN_channel_get_voice_info(eng, chan, "SAMPLE_RATE"));

        // Print some information about the voice on this channel,
        // sample rate can be useful for direct audio playback
        Debug.Log("The voice is " + cerevoice_eng.CPRCEN_channel_get_voice_info(eng, chan, "VOICE_NAME") + " on channel " + chan + " and the sample rate is " + sampleRate);

        // Set our callback handler - synthesised speech is returned
        // in the callback, along with transcription information. A
        // callback delegate object needs creating and keeping alive
        // to avoid garbage collection issues.
        cerevoice_eng.ChannelCallback cb = new cerevoice_eng.ChannelCallback(CallbackHandler);
        cerevoice_eng.SetChannelCallback(eng, chan, cb);

        // Set piping, turned off here for simpler audio/visual alignment. In low-latency
        // applications the pipe length should not be overridden.
        cerevoice_eng.CPRCEN_channel_set_pipe_length(eng, chan, 0);

        // Synthesise
        Debug.Log("Speak input '" + input + "'");
        cerevoice_eng.CPRCEN_engine_channel_speak(eng, chan, input, input.Length, 1);

        // Close channel to prevent concurrent synthesis
        Debug.Log("Closing channel");
        cerevoice_eng.CPRCEN_engine_channel_close(eng, chan);
        GC.KeepAlive(cb);
    }

    [MonoPInvokeCallback(typeof(cerevoice_eng.ChannelCallback))]
    // This is called per 'phrase' of input (currently on CPRC thread), static for
    // compatibility with il2cpp
    static void CallbackHandler(IntPtr abufp, IntPtr userdatap)
    {
        // User data pointer not supported on C#, use class variables
        SWIGTYPE_p_CPRC_abuf_trans trans;
        int i; 
        int wav_mk; // start index of audio data
        int wav_done; // end index of audio data (inclusive)
        int wav_added; // amount of new samples
        int trans_mk; // start index of trans event (inclusive)
        int trans_done; // end index of trans event (inclusive)
        string trans_name;
        float start;
        int viseme_id;
        string viseme_name;

        // First convert our abuf pointer into a C# audio buffer
        SWIGTYPE_p_CPRC_abuf abuf = new SWIGTYPE_p_CPRC_abuf(abufp, false);


        // Used for processing when a min/max phone range has been set
        wav_mk = cerevoice_eng.CPRC_abuf_wav_mk(abuf);
        wav_done = cerevoice_eng.CPRC_abuf_wav_done(abuf);
        wav_added = cerevoice_eng.CPRC_abuf_added_wav_sz(abuf);
        trans_mk = cerevoice_eng.CPRC_abuf_trans_mk(abuf);
        trans_done = cerevoice_eng.CPRC_abuf_trans_done(abuf);

        Debug.Log("Callback fired wav_mk " + wav_mk + ", wav_done " + wav_done + ", trans_mk " + trans_mk + ", trans_done " + trans_done);

        // (Re)-initialize viseme list of phrase
        List<Viseme> visemes = new List<Viseme>();

        // Process the transcription buffer, it contains markers, and timings
        for (i = trans_mk; i <= trans_done; i++)
        {
            trans = cerevoice_eng.CPRC_abuf_get_trans(abuf, i);
            trans_name = cerevoice_eng.CPRC_abuf_trans_name(trans);
            start = cerevoice_eng.CPRC_abuf_trans_start(trans);
            Debug.Log("trans " + i + " name " + trans_name + " start " + start);

            // Phoneme processing
            if (cerevoice_eng.CPRC_abuf_trans_type(trans) == CPRC_ABUF_TRANS_TYPE.CPRC_ABUF_TRANS_PHONE)
            {
                // retrieve SAPI viseme ID from trans
                viseme_id = cerevoice_eng.CPRC_abuf_trans_sapi_viseme(trans);

                // check if valid phone is being output and convert viseme ID to Viseme object
                if (viseme_id != -1)
                {
                    viseme_name = ID2Vis(viseme_id);
                    Viseme viseme = new Viseme { name = viseme_name, start = start };

                    // add viseme to viseme queue
                    visemes.Add(viseme);
                }
            }

            // Marker processing
            if (cerevoice_eng.CPRC_abuf_trans_type(trans) == CPRC_ABUF_TRANS_TYPE.CPRC_ABUF_TRANS_MARK)
            {
                if (trans_name == "happy" || trans_name == "sad" || trans_name == "calm" || trans_name == "cross")
                {
                    Viseme viseme = new Viseme { name = trans_name, start = start };
                    visemes.Add(viseme);
                }
            }
        }

        // Unity needs audio as float array, with samples between -1 and 1
        Debug.Log("convert " + wav_added + " samples and enqueue");
        float[] floatArr = new float[wav_added];
        for (i = wav_mk; i <= wav_done; i++) 
        {
            floatArr[i-wav_mk] = cerevoice_eng.CPRC_abuf_wav(abuf, i) / (float)32768.0;
        }
        RawPhrase rawphrase = new RawPhrase { floatArr = floatArr, visemeList = visemes };
        RawPhrases.Enqueue(rawphrase);
        Debug.Log("callback done");
    }

    static string ID2Vis(int viseme_id)
    {
        string viseme_name = "Silence";

        switch (viseme_id)
        {
            case 2:
                viseme_name = "PhonemeAA";
                break;
            case 4:
                viseme_name = "PhonemeEH";
                break;
            case 3:
                viseme_name = "PhonemeOH";
                break;
            case 9:
                viseme_name = "PhonemeAW";
                break;
            case 1:
                viseme_name = "PhonemeAH";
                break;
            case 19:
                viseme_name = "PhonemeCDG";
                break;
            case 11:
                viseme_name = "PhonemeEH";
                break;
            case 5:
                viseme_name = "PhonemeCDG";
                break;
            case 18:
                viseme_name = "PhonemeFV";
                break;
            case 20:
                viseme_name = "PhonemeCDG";
                break;
            case 12:
                viseme_name = "PhonemeCDG";
                break;
            case 6:
                viseme_name = "PhonemeEE";
                break;
            case 14:
                viseme_name = "PhonemeLL";
                break;
            case 8:
                viseme_name = "PhonemeOH";
                break;
            case 10:
                viseme_name = "PhonemeOH";
                break;
            case 21:
                viseme_name = "PhonemeBMP";
                break;
            case 13:
                viseme_name = "PhonemeCDG";
                break;
            case 15:
                viseme_name = "PhonemeCDG";
                break;
            case 16:
                viseme_name = "PhonemeJJ";
                break;
            case 17:
                viseme_name = "PhonemeTH";
                break;
            case 7:
                viseme_name = "PhonemeOH";
                break;
            case 0:
                viseme_name = "Silence";
                break;
        }

        return viseme_name;
    }


    void Update()
    {
        if (RawPhrases.Count > 0 && !audiosource.isPlaying)
        {
            currRawPhrase = RawPhrases.Dequeue();

            // create AudioClip of correct length and sample rate
            AudioClip speech = AudioClip.Create("speech", currRawPhrase.floatArr.Length, 1, sampleRate, false);
            speech.SetData(currRawPhrase.floatArr, 0);
            Debug.Log("add speech and visemes to PlayQueue");
            PlayQueue(speech, currRawPhrase.visemeList);
        }
    }

    void PlayQueue(AudioClip speech, List<Viseme> visemeList)
    {
        audiosource.clip = speech;
        audiosource.Play();
        VisemePhrase(visemeList);
    }

    void VisemePhrase(List<Viseme> visemes)
    {
        Animator UMAAnimator = GameObject.Find("Troll").GetComponent<Animator>();

        foreach (Viseme viseme in visemes)
        {
            StartCoroutine(DelayedAnim(UMAAnimator, viseme.name, viseme.start));
        }
    }

    IEnumerator DelayedAnim(Animator Animator, string visemeName, float startTime)
    {
        // Adjust delay accordingly based on processing time of target machine 
        yield return new WaitForSeconds(startTime + 0.1f); 
        Animator.SetTrigger(visemeName);
    }

}
